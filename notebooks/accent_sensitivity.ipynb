{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkXhZgiUzVVv",
    "outputId": "0f346db8-fd2d-4359-9bce-cf66f8567276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_PATH=/content/VCTK-Corpus-0.92\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"accent-embeddings\")\n",
    "\n",
    "%env DATASET_PATH=/content/VCTK-Corpus-0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G3gWm3Xp_9es"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Tdbx5bc7zILF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchaudio.transforms import GriffinLim\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from text import text_to_sequence, sequence_to_text\n",
    "\n",
    "from hyper_params import *\n",
    "from train import load_data\n",
    "\n",
    "from models.tacotron2 import Tacotron2\n",
    "from models.wav2vec_id import Wav2VecID\n",
    "from models.wav2vec_asr import Wav2VecASR\n",
    "from multitask import AccentedMultiTaskNetwork, Task\n",
    "from metrics import *\n",
    "\n",
    "from transformers import Wav2Vec2Processor \n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnfN4M8SvLAs",
    "outputId": "bf823fbb-214e-40b3-fbda-36b632e19640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loading Audio Lengths\n",
      "Number of samples:  37372\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = load_data(TrainingParams(val_size=0.1, batch_size=1), DataParams(filter_length=800, sample_rate=16000, win_length=800, hop_length=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF3grqZmXtgB"
   },
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "NRGDWVbrPRqj",
    "outputId": "bfe8fae4-b909-41b4-9e04-1f4bb2882104"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maparande\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/aparande/uncategorized/runs/154qlvqc\" target=\"_blank\">devoted-blaze-27</a></strong> to <a href=\"https://wandb.ai/aparande/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3lllyvm6:v3, 3901.45MB. 1 files... Done. 0:0:0\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('g-luo/accent_embeddings/model-3lllyvm6:v3', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qcMuTc9PzMw8"
   },
   "outputs": [],
   "source": [
    "tacotron = Tacotron2(TacotronParams())\n",
    "tts_task = Task(model=tacotron, loss=None, learning_rate=1e-3, weight_decay=1e-6, name='TTS', loss_weight=1, metrics=[MSE()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eUwbsZO5XTNi"
   },
   "outputs": [],
   "source": [
    "asr = Wav2VecASR(Wav2VecASRParams())\n",
    "asr_task = Task(model=asr, loss=None, learning_rate=1e-5, weight_decay=0, name='ASR', loss_weight=0.5, metrics=[WERAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2abVEKYqP63c"
   },
   "outputs": [],
   "source": [
    "accent_id = Wav2VecID(Wav2VecIDParams())\n",
    "accent_id_task = Task(model=accent_id, loss=None, learning_rate=1e-5, name='ID', weight_decay=0, loss_weight=1, metrics=[SoftmaxAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8r4h7zkQDJZ",
    "outputId": "056c507f-85c6-4fbd-b564-2e622b5216f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mp = MultiTaskParams(hidden_dim=[13], in_dim=1024, alternate_epoch_interval = 2)\n",
    "model = AccentedMultiTaskNetwork.load_from_checkpoint(f\"{artifact_dir}/model.ckpt\", params=mp, tasks=[accent_id_task, asr_task, tts_task]).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OXfecneTX-dK"
   },
   "outputs": [],
   "source": [
    "def predict_batch(batch, predict=False, accent_embed=None):\n",
    "  batch[\"wav2vec_input\"] = batch[\"wav2vec_input\"].cuda()\n",
    "  wav2vec_feats = model.get_wav2vec_features(batch)\n",
    "\n",
    "  if accent_embed is None:\n",
    "    accent_embed = model.bottleneck(wav2vec_feats)\n",
    "\n",
    "  outs = dict()\n",
    "\n",
    "  if predict:\n",
    "    batch[\"text_tensor\"] = batch[\"text_tensor\"].cuda()\n",
    "    for task in model.tasks:\n",
    "      x = task.model.parse_batch(batch)\n",
    "      outs[task.name] = task.model(x, accent_embed)\n",
    "\n",
    "  return accent_embed, outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwILALx1Xyz4"
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_V_7_Hutyyel"
   },
   "outputs": [],
   "source": [
    "label_map = {\n",
    "  4: 'English',\n",
    "  9: 'Scottish',\n",
    "  8: 'NorthernIrish',\n",
    "  6: 'Irish',\n",
    "  5: 'Indian',\n",
    "  12: 'Welsh',\n",
    "  11: 'Unknown',\n",
    "  0: 'American',\n",
    "  3: 'Canadian',\n",
    "  10: 'SouthAfrican',\n",
    "  1: 'Australian',\n",
    "  7: 'NewZealand',\n",
    "  2: 'British'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJJiBuHvxo7l",
    "outputId": "27ce4b3b-94f5-4945-f992-badaa467e2bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/3737 [00:00<03:09, 19.64it/s]\n"
     ]
    }
   ],
   "source": [
    "accents = []\n",
    "embeddings = []\n",
    "for i, batch in enumerate(tqdm(val_loader)):\n",
    "  embedding, x = predict_batch(batch)\n",
    "  \n",
    "  accents.append(label_map[batch[\"accents\"].data.cpu().numpy()[0]])\n",
    "  embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM6GrpKSGE-n",
    "outputId": "ecaee074-71fc-4a3a-86ca-31dc434c041c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 27822.91it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_embed = {}\n",
    "accent_counts = {}\n",
    "for embed, accent in tqdm(zip(embeddings, accents)):\n",
    "  if accent in avg_embed:\n",
    "    avg_embed[accent] += embed\n",
    "  else:\n",
    "    avg_embed[accent] = embed\n",
    "\n",
    "  accent_counts[accent] = accent_counts.get(accent, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WJjCuaUBHtlr"
   },
   "outputs": [],
   "source": [
    "accent_embeds = { accent: avg_embed[accent] / accent_counts[accent] for accent in accent_counts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zxcTgtN5gkj_"
   },
   "outputs": [],
   "source": [
    "accented_batches = { accent: [] for accent in accent_embeds }\n",
    "\n",
    "for i, batch in enumerate(val_loader):\n",
    "  accent = label_map[batch[\"accents\"].data.numpy()[0]]\n",
    "  if len(accented_batches[accent]) < 25:\n",
    "    accented_batches[accent].append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE3H4o5rc3zT"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for orig_accent in accented_batches:\n",
    "  for batch in accented_batches[orig_accent]:\n",
    "    embedding, out = predict_batch(batch, predict=True)\n",
    "\n",
    "    for task in out:\n",
    "      if task == \"TTS\":\n",
    "        out[task][\"mfcc\"] = out[task].pop(\"mel_out_postnet\")\n",
    "      out[task] = [out[task]]\n",
    "\n",
    "    asr_targets = [model.tasks[1].model.get_targets(batch)]\n",
    "    orig_asr_wer = model.tasks[1].metrics[0](out[\"ASR\"], asr_targets)\n",
    "\n",
    "    for target_accent in accent_embeds:\n",
    "      accent_scores = np.zeros(len(model.tasks))\n",
    "      embedding, accented_out = predict_batch(batch, predict=True, accent_embed=accent_embeds[target_accent])\n",
    "\n",
    "      for task in accented_out:\n",
    "        accented_out[task] = [accented_out[task]]\n",
    "\n",
    "      for i, task in enumerate(model.tasks):\n",
    "        if task.name == \"ASR\":\n",
    "          accent_scores[i] = orig_asr_wer - task.metrics[0](accented_out[task.name], asr_targets)\n",
    "        else:\n",
    "          accent_scores[i] = task.metrics[0](accented_out[task.name], out[task.name])\n",
    "\n",
    "      results.append((orig_accent, target_accent, *accent_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTZenKwMragn"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJCS0R_7rdYU"
   },
   "outputs": [],
   "source": [
    "with open(\"results.pkl\") as f:\n",
    "  pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "accent-sensitivity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
